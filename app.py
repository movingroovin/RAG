import os
import gradio as gr
import requests
from dotenv import load_dotenv
from langchain_groq import ChatGroq
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_core.chat_history import InMemoryChatMessageHistory

# è¼‰å…¥ .env æª”æ¡ˆä¸­çš„ç’°å¢ƒè®Šæ•¸
load_dotenv()

def get_groq_models():
    """
    å¾ Groq API ç²å–å¯ç”¨æ¨¡å‹æ¸…å–®
    """
    api_key = os.environ.get("GROQ_API_KEY")
    if not api_key:
        return ["openai/gpt-oss-120b"] # é è¨­æ¨¡å‹
    
    url = "https://api.groq.com/openai/v1/models"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    
    try:
        response = requests.get(url, headers=headers)
        if response.status_code == 200:
            models_data = response.json()
            # å–å¾—æ¨¡å‹ ID ä¸¦ä»¥å­—æ¯åºæ’åº
            model_ids = [model['id'] for model in models_data['data']]
            return sorted(model_ids)
        else:
            print(f"ç„¡æ³•ç²å–æ¨¡å‹: {response.status_code}")
            return ["openai/gpt-oss-120b"]
    except Exception as e:
        print(f"ç²å–æ¨¡å‹æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return ["openai/gpt-oss-120b"]

# è¨˜æ†¶é«”å­˜å„²
store = {}

def get_session_history(session_id: str) -> InMemoryChatMessageHistory:
    if session_id not in store:
        store[session_id] = InMemoryChatMessageHistory()
    return store[session_id]

def chat_response(message, history, model_name):
    """
    è™•ç†ç”¨æˆ¶è¨Šæ¯ä¸¦è¿”å› AI å›æ‡‰
    """
    try:
        # ä¾ç…§é¸æ“‡çš„æ¨¡å‹å‹•æ…‹åˆå§‹åŒ– LLM
        llm = ChatGroq(
            model=model_name,
            temperature=0.7,
            max_tokens=1000
        )

        # å»ºç«‹æç¤ºæ¨¡æ¿
        prompt = ChatPromptTemplate.from_messages([
            ("system", "You are a helpful assistant."),
            MessagesPlaceholder(variable_name="history"),
            ("human", "{input}")
        ])

        # å»ºç«‹éˆä¸¦åŠ ä¸Šæ­·å²è¨˜éŒ„åŠŸèƒ½
        chain = prompt | llm
        chain_with_history = RunnableWithMessageHistory(
            chain,
            get_session_history,
            input_messages_key="input",
            history_messages_key="history"
        )

        print(f"ä½¿ç”¨æ¨¡å‹: {model_name} | ç”¨æˆ¶è¨Šæ¯: {message}")
        
        response = chain_with_history.invoke(
            {"input": message},
            config={"configurable": {"session_id": "default"}}
        )
        
        # Gradio 5.0+ ä½¿ç”¨å­—å…¸æ ¼å¼
        history.append({"role": "user", "content": message})
        history.append({"role": "assistant", "content": response.content})
        
        return "", history
    except Exception as e:
        error_msg = f"ç™¼ç”ŸéŒ¯èª¤: {str(e)}"
        print(error_msg)
        history.append({"role": "user", "content": message})
        history.append({"role": "assistant", "content": error_msg})
        return "", history

def clear_history():
    """
    æ¸…é™¤å°è©±æ­·å²
    """
    if "default" in store:
        store["default"] = InMemoryChatMessageHistory()
    return []

# å–å¾—å¯ç”¨æ¨¡å‹
available_models = get_groq_models()

# å‰µå»º Gradio ä»‹é¢
with gr.Blocks(title="LangChain + Gradio å°è©±æ‡‰ç”¨", theme=gr.themes.Soft()) as demo:
    gr.Markdown("# ğŸ¤– LangChain + Groq å°è©±æ‡‰ç”¨")
    
    with gr.Row():
        with gr.Column(scale=4):
            gr.Markdown("èˆ‡ AI é€²è¡Œå°è©±ï¼è«‹è¨˜å¾—è¨­å®šæ‚¨çš„ Groq API é‡‘é‘°ã€‚")
        with gr.Column(scale=1):
            model_selector = gr.Dropdown(
                choices=available_models,
                value=available_models[0] if available_models else "openai/gpt-oss-120b",
                label="é¸æ“‡ Groq æ¨¡å‹",
                interactive=True
            )

    chatbot = gr.Chatbot(
        height=500,
        show_label=False,
        container=True,
        # type="messages" # æ˜ç¢ºæŒ‡å®šä½¿ç”¨è¨Šæ¯æ ¼å¼
    )

    with gr.Row():
        msg = gr.Textbox(
            placeholder="è¼¸å…¥æ‚¨çš„è¨Šæ¯...",
            show_label=False,
            container=False,
            scale=7
        )
        submit_btn = gr.Button("é€å‡º", scale=1, variant="primary")
        clear_btn = gr.Button("æ¸…é™¤å°è©±", scale=1)

    gr.Markdown("---")
    gr.Markdown("**ä½¿ç”¨èªªæ˜ï¼š**")
    gr.Markdown("- åœ¨å³ä¸Šæ–¹ä¸‹æ‹‰é¸å–®é¸æ“‡æ‚¨æƒ³ä½¿ç”¨çš„ Groq æ¨¡å‹")
    gr.Markdown("- åœ¨ä¸‹æ–¹è¼¸å…¥æ¡†è¼¸å…¥æ‚¨çš„å•é¡Œæˆ–è¨Šæ¯")
    gr.Markdown("- é»æ“Šã€Œé€å‡ºã€æŒ‰éˆ•æˆ–æŒ‰ Enter ç™¼é€è¨Šæ¯")
    gr.Markdown("- é»æ“Šã€Œæ¸…é™¤å°è©±ã€æŒ‰éˆ•ä¾†é‡æ–°é–‹å§‹å°è©±")
    gr.Markdown("- è«‹ç¢ºä¿å·²è¨­å®šæœ‰æ•ˆçš„ Groq API é‡‘é‘°")

    # è¨­å®šäº‹ä»¶è™•ç†
    msg.submit(chat_response, [msg, chatbot, model_selector], [msg, chatbot])
    submit_btn.click(chat_response, [msg, chatbot, model_selector], [msg, chatbot])
    clear_btn.click(clear_history, outputs=chatbot)

if __name__ == "__main__":
    # å•Ÿå‹•æ‡‰ç”¨ç¨‹å¼
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        show_error=True
    )